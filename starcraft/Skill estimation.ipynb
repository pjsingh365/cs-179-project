{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pystan\n",
    "\n",
    "# Load training data and reduce (subsample) if desired\n",
    "\n",
    "# Read thru file to get numeric ids for each player \n",
    "with open('train.csv') as f: lines = f.read().split('\\n')\n",
    "\n",
    "p = 0; playerid = {};\n",
    "for i in range(len(lines)):\n",
    "    csv = lines[i].split(',');\n",
    "    if len(csv) != 10: continue;   # parse error or blank line\n",
    "    player0,player1 = csv[1],csv[4];\n",
    "    if player0 not in playerid: playerid[player0]=p; p+=1;\n",
    "    if player1 not in playerid: playerid[player1]=p; p+=1;\n",
    "\n",
    "nplayers = len(playerid)\n",
    "playername = ['']*nplayers\n",
    "for player in playerid: playername[ playerid[player] ]=player;  # id to name lookup\n",
    "\n",
    "\n",
    "# Sparsifying parameters (discard some training examples):\n",
    "pKeep = 1.0   # fraction of edges to consider (immed. throw out 1-p edges)\n",
    "nEdge = 3     # try to keep nEdge opponents per player (may be more; asymmetric)\n",
    "nKeep = 5     # keep at most nKeep games per opponent pairs (play each other multiple times)\n",
    "\n",
    "nplays, nwins = np.zeros( (nplayers,nplayers) ), np.zeros( (nplayers,nplayers) );\n",
    "for i in range(len(lines)):\n",
    "    csv = lines[i].split(',');\n",
    "    if len(csv) != 10: continue;   # parse error or blank line\n",
    "    a,b = playerid[csv[1]],playerid[csv[4]];\n",
    "    aw,bw = csv[2]=='[winner]',csv[5]=='[winner]';\n",
    "    if (np.random.rand() < pKeep):\n",
    "        if (nplays[a,b] < nKeep) and ( ((nplays[a,:]>0).sum() < nEdge) or ((nplays[:,b]>0).sum() < nEdge) ):\n",
    "            nplays[a,b] += 1; nplays[b,a]+=1; nwins[a,b] += aw; nwins[b,a] += bw;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nplayers # number of unique players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC vs Stats\n"
     ]
    }
   ],
   "source": [
    "playerid # map from playername -> playerID\n",
    "playername[0] # list of playernames indexed by their ID\n",
    "print(playername[0], \"vs\", playername[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nplays[0,1] # number of games between player 0 and player 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwins[0,1] # number of wins between player 0 and player 1\n",
    "np.max(nwins) # maximum number of wins against a single opponent is 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9354.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(nplays)  # number of player vs player combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pystan\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "win = []\n",
    "PA = []\n",
    "PB = []\n",
    "for index, wins in np.ndenumerate(nwins):\n",
    "    if wins == 0: continue\n",
    "    win.append(int(wins))\n",
    "    PA.append(index[0] + 1)           # increment so we can index starting at 1\n",
    "    PB.append(index[1] + 1)           # player 0 is now player 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 2, 4, 4, 2]  # of wins PA had over PB\n",
      "[1, 1, 1, 1, 1, 1]  PA's ID\n",
      "[2, 4, 6, 7, 8, 9]  PB's ID\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3321"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(win[:6], \" # of wins PA had over PB\") \n",
    "print(PA[:6], \" PA's ID\") \n",
    "print(PB[:6], \" PB's ID\")\n",
    "len(win)            # total number of games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Stan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_model = \"\"\"\n",
    "data {\n",
    "  int<lower=1> N;             # Total number of players i.e 999\n",
    "  int<lower=1> E;             # number of matchups (3321)\n",
    "  real<lower=0> scale;        # scale value for probability computation\n",
    "  int<lower=1,upper=5> win[E];        # PA wins vs PB\n",
    "  int PA[E];                  # player info between each matchup\n",
    "  int PB[E];                  # \n",
    "}\n",
    "parameters {\n",
    "  vector<lower=0> [N] skill;           # skill values for each player\n",
    "}\n",
    "\n",
    "model{\n",
    "  for (i in 1:N){ skill[i]~normal(0,3); }\n",
    "  for (i in 1:E){\n",
    "    win[i] ~ binomial_logit(5, (scale)*(skill[PA[i]]-skill[PB[i]]) );\n",
    "  }   # win probability is a binomial_logit function of skill difference (0-5)\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "try:     # load it if already compiled\n",
    "    sm = pickle.load(open('skill_model.pkl', 'rb'))\n",
    "except:  # ow, compile and save compiled model\n",
    "    sm = pystan.StanModel(model_code = skill_model)\n",
    "    with open('skill_model.pkl', 'wb') as f: pickle.dump(sm, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_data = {\n",
    "    'N': 999,\n",
    "    'E': 3321,\n",
    "    'scale': 0.7,\n",
    "    'win': win,\n",
    "    'PA': PA,\n",
    "    'PB': PB\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can perform MCMC on the model, and extract the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = sm.sampling(data=skill_data, iter=1000, chains=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = fit.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we just want the mean estimate for each player's skill level, just take the empirical average over the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91419291 0.63417521 0.63382915 0.22968477 0.71563908 0.99406587\n",
      " 0.46897308 0.56226324 0.20376113 1.10664458 1.35272825 0.81528501\n",
      " 0.77868997 0.60891634 0.88954497 1.09831877 2.10070943 1.14252531\n",
      " 0.65561437 1.17296885 1.1526062  1.0068496  1.04484137 0.88917657\n",
      " 0.62157679 1.61050972 1.46865394 0.67415341 0.42356093 0.49123345\n",
      " 1.1598095  2.67986512 0.59348842 0.77371793 1.72773273 1.8362436\n",
      " 1.60199866 1.42866206 0.44979782 1.29455009 1.52843747 0.29902975\n",
      " 0.6356594  0.35659742 1.07123725 1.31890913 0.7345776  0.56698989\n",
      " 1.23046146 0.58193712 0.95676694 0.80324227 2.04474336 1.00956325\n",
      " 1.06343389 1.00313218 0.49327324 0.50650478 2.25856055 0.40061928\n",
      " 0.97664546 0.62385614 1.24585221 0.80325273 0.40411461 1.40611768\n",
      " 1.38305825 0.73168187 0.69123231 0.4835299  0.83794166 1.56126061\n",
      " 2.59079869 0.95630684 0.26544802 1.40863961 0.68986445 1.47535498\n",
      " 1.0888421  1.57935093 0.33584778 0.48146559 1.43380131 1.37108855\n",
      " 0.61115823 1.15277081 0.87624735 2.86226518 0.51155722 2.92870589\n",
      " 1.55640352 2.51348703 1.30317307 2.73764313 1.17053039 1.50143864\n",
      " 0.98436632 2.73821511 2.56626663 0.6725031  0.93235005 1.6621329\n",
      " 0.75585069 1.07540651 0.70839457 1.06242196 1.19980926 1.23624065\n",
      " 1.25570742 0.60251331 1.52873877 2.24243851 1.10734094 2.12595714\n",
      " 2.60940142 1.56689309 2.54070024 1.63247205 2.67153281 1.28523017\n",
      " 0.6814821  0.72182237 0.6318761  0.92161078 1.63660965 1.01726803\n",
      " 0.70661485 2.51057287 1.05118856 1.93810723 0.73870565 1.82824512\n",
      " 0.27200651 0.42507006 2.78110642 0.70678009 2.09314868 1.7807508\n",
      " 1.05789851 0.87942053 1.89548838 2.87111977 2.26148403 1.31952318\n",
      " 2.54097984 2.48647031 1.03623471 2.86968316 0.70026674 1.34768979\n",
      " 0.61411691 0.31324852 0.97408427 1.8373528  2.66489984 0.90058764\n",
      " 1.28408005 1.30723465 0.72150841 1.31070777 1.23477648 0.64703682\n",
      " 1.40916863 1.39252062 1.68491178 2.7512038  2.57193007 1.13320187\n",
      " 1.42026046 0.97382049 0.65832361 0.7299831  2.18305378 2.35390001\n",
      " 2.77990808 2.0525968  0.95028313 1.82825413 0.83842979 0.69674611\n",
      " 0.73799969 2.01456584 1.54090787 1.47598223 1.48228503 1.45037863\n",
      " 2.62806175 2.23867119 1.60685656 2.60414979 1.92401157 0.46640135\n",
      " 1.46427772 2.60348615 2.98334614 2.76965434 1.40121642 0.82952032\n",
      " 1.8893441  2.59325975 1.41700428 0.69916458 1.59559698 0.30204256\n",
      " 0.43118633 0.60738931 0.63642429 0.52281317 0.50177635 2.0672579\n",
      " 0.8944584  0.83613542 0.48293833 0.52534977 0.79146769 1.14980369\n",
      " 0.59964918 0.71925758 3.02527495 0.80353979 0.58716143 2.63023762\n",
      " 1.22618057 0.69564671 0.82497285 1.30164028 1.12876342 2.22935143\n",
      " 1.52571441 0.79443112 1.07643997 2.98368306 2.03737016 0.55063351\n",
      " 0.82495322 0.59025313 0.34272262 1.44116194 2.72277899 1.19384781\n",
      " 0.66390144 2.5694734  0.70751323 1.13095471 0.42618847 1.45468632\n",
      " 2.44019577 2.81355964 1.61723084 1.66641705 2.75678998 2.58836793\n",
      " 0.7017916  2.82456795 0.68839186 0.95062568 1.30355662 2.13081365\n",
      " 0.90165999 1.42077256 1.40051692 1.61737791 0.97244148 0.70659533\n",
      " 0.77287341 2.83646246 1.7013786  1.5571455  2.82820921 1.91541513\n",
      " 2.00020546 2.00870983 1.20345726 2.68316826 2.19481916 2.64821278\n",
      " 1.66059058 2.77722981 1.17246471 0.74419767 1.28644215 0.2504745\n",
      " 1.42125602 1.23785251 1.32521418 1.79408904 2.08565277 1.05651539\n",
      " 2.69448748 0.88010435 2.1696524  2.49268807 1.68935584 0.44614642\n",
      " 2.68639204 0.96795593 1.08501319 1.22005984 0.96489631 0.53868226\n",
      " 0.32994992 1.47967713 1.36206554 1.53281857 2.28912723 0.96997218\n",
      " 2.23479656 1.2211078  0.44096226 0.74791261 2.69444508 1.42755906\n",
      " 1.85601586 0.92398942 1.94651939 0.82912011 0.30424358 0.88638369\n",
      " 0.9410811  2.52325364 0.75779119 2.55555025 1.56135739 2.70352852\n",
      " 0.61735595 2.88601255 2.16590109 1.39776068 1.67236301 1.69875229\n",
      " 1.35104369 0.96055741 2.61962454 1.5136097  1.47054348 2.21561353\n",
      " 2.27116314 2.43767943 2.49018969 2.66396256 2.86755826 3.45039525\n",
      " 2.62600211 1.06498494 2.4748025  1.41018548 2.5983914  2.04731893\n",
      " 1.31205716 1.78928577 1.93856287 1.52060911 1.4908341  2.13945552\n",
      " 1.62815759 2.71947422 1.49665786 2.92425028 2.71922706 2.28072336\n",
      " 2.35522198 1.98088575 2.35978691 1.3416732  0.33905245 0.97399732\n",
      " 0.68580506 2.82595997 0.56833181 2.67136919 2.61779249 1.50550428\n",
      " 0.80352367 1.10512634 1.09643687 2.00853493 0.98706899 2.95086619\n",
      " 2.0030875  2.62715919 0.6103777  1.03976772 1.96377134 2.89976585\n",
      " 0.3596566  1.10555774 2.16148556 1.36415627 1.40016196 2.7798917\n",
      " 2.02459014 2.76955818 1.27957872 1.05202765 0.73552774 1.23906698\n",
      " 1.26352562 2.2673901  0.59349379 2.66834736 1.17486261 2.12862214\n",
      " 1.36349148 2.53853841 2.63994197 0.59718835 2.08776072 2.47277036\n",
      " 3.27170703 2.39978915 1.45040987 0.64791768 1.95412671 1.7981592\n",
      " 2.45808494 2.54789997 0.56813969 0.87586738 2.72479508 2.32030294\n",
      " 2.45830282 0.58012768 2.3202731  1.21086378 2.26704971 2.5745087\n",
      " 0.93536086 1.34363531 1.87211294 1.09887047 0.74125576 0.30668644\n",
      " 1.52988013 1.63387261 2.60845154 2.05616562 0.44084671 0.58220629\n",
      " 1.15337928 1.38593849 1.80554952 2.38865174 2.10851337 2.65180576\n",
      " 0.32850175 3.02130674 1.45471342 2.55621942 0.8419741  2.36908297\n",
      " 1.67294013 2.13902229 2.42014284 1.47503189 1.23117897 2.82967589\n",
      " 1.54566776 1.33391073 1.83657467 1.6831819  2.6268732  2.86481966\n",
      " 2.81171376 0.64624183 2.66044828 1.17034554 1.46851794 1.7858347\n",
      " 0.40589006 2.24485908 1.03480566 1.42531858 2.56376283 2.60513522\n",
      " 2.89005263 1.72037387 1.456316   0.83119486 1.18793169 2.70353356\n",
      " 1.34022025 2.08210769 2.14810841 1.6113772  2.67571416 2.24321551\n",
      " 2.20398796 2.63561656 1.23036553 1.5906681  2.63738104 0.38301805\n",
      " 2.06997848 2.96730553 1.40309998 0.9878838  1.1362789  1.23371485\n",
      " 2.2025636  2.03253994 1.40087415 1.22435759 2.47034225 2.96441027\n",
      " 1.3103591  1.70955378 1.34915271 1.09900465 1.80026446 2.37854813\n",
      " 2.66198718 2.70685755 2.22995345 2.6004148  2.6974308  2.66619609\n",
      " 1.46138446 1.08586349 3.43943098 2.06640215 0.45450705 1.91291076\n",
      " 2.49154144 1.16734449 2.13171041 1.48337617 1.13457327 2.42314617\n",
      " 2.71824771 1.3353874  2.69858285 1.46989416 2.23248226 1.69335189\n",
      " 1.90440975 2.98472555 1.98861563 2.3041461  1.32450805 1.77581736\n",
      " 2.59955641 2.78371832 2.38733135 2.81392969 0.62065872 0.7851369\n",
      " 1.10282632 2.97733831 2.75676173 1.3173599  3.0148084  2.86944159\n",
      " 1.21166322 1.0377215  0.65060742 1.39896435 2.96867957 2.95455547\n",
      " 2.99849968 2.62501028 2.84973188 2.75480522 1.70598076 2.12246147\n",
      " 2.97367161 1.78999836 2.14188655 0.46571486 2.25684484 1.47823775\n",
      " 2.91222365 2.7804157  2.12258289 1.13789477 3.24204148 0.97383915\n",
      " 1.09367861 2.16727882 1.25602104 3.1216904  2.73677498 2.01987375\n",
      " 1.11098166 2.75251589 2.34664645 2.71055272 2.88448832 1.31691344\n",
      " 2.49653255 1.36544189 2.9398132  2.86590542 1.71354451 0.67405526\n",
      " 1.16891124 1.3313766  2.00063717 2.76274331 2.97076887 1.30681979\n",
      " 1.08397626 2.48942273 1.98160318 2.37702425 2.45635058 2.44659505\n",
      " 1.11908256 0.51232385 3.18632059 2.20373158 1.98294562 1.69639299\n",
      " 3.10061517 2.77873953 1.51287079 2.44668816 0.61339467 1.74928473\n",
      " 1.83615619 2.0408226  0.9265601  1.62485387 2.41296359 2.04706471\n",
      " 0.59827729 3.12667144 1.54272684 0.9509889  2.48200814 2.84423752\n",
      " 2.21574657 2.29546206 2.14486224 1.8731682  1.91582897 0.90982938\n",
      " 2.45061343 1.78042331 2.44156789 0.81350113 1.33903366 1.73668988\n",
      " 0.54098685 1.8194708  0.79111064 2.87855398 0.52011246 0.82873948\n",
      " 1.81622171 2.17783278 1.9266299  1.11777312 2.16672729 1.44795047\n",
      " 1.02404049 0.52801173 2.8049004  1.9633099  2.62138574 1.04694816\n",
      " 0.40903253 1.82498692 1.76303293 2.22326646 1.02417392 2.33129223\n",
      " 1.72998645 2.71130885 2.69217668 2.61139583 1.65169622 0.50448571\n",
      " 2.98635608 0.87504075 1.33608423 2.25247809 3.30331654 2.56462435\n",
      " 2.76140574 1.47963985 2.67948226 3.17550528 2.75614392 2.93674587\n",
      " 0.64680618 2.92148951 1.4101805  1.35150806 0.99011662 1.01592144\n",
      " 2.87477263 1.49562446 1.07630074 1.46957682 2.62322006 2.51486929\n",
      " 1.45209255 2.89242735 1.11491979 1.76368679 1.212307   0.72227422\n",
      " 2.96576101 1.74032159 1.24974474 0.89206768 1.14536461 0.83666148\n",
      " 0.93458044 1.23711173 0.87944894 1.37748139 1.570154   2.14980034\n",
      " 0.56621259 2.93719859 2.90271351 1.82317045 2.4656522  0.70332729\n",
      " 2.85308379 1.11173934 2.51349947 1.04601578 1.14350801 1.34716795\n",
      " 2.55274328 0.94016132 2.27154424 1.46907554 2.6718339  0.96066419\n",
      " 2.63898884 0.30871347 3.15808136 1.26374776 0.72972825 1.61783358\n",
      " 1.08261511 1.93780095 1.7687708  2.50452992 1.93630085 2.64962847\n",
      " 2.68801678 0.97218551 1.46645933 2.37587628 2.63677386 2.53451086\n",
      " 0.99547505 2.50983542 2.50659418 2.17022477 1.95052567 1.31672212\n",
      " 1.70228114 2.56799691 1.87389862 2.39391838 1.73417191 1.98024971\n",
      " 2.39743869 1.46729101 0.9531031  2.24425364 1.542489   2.33389555\n",
      " 2.12708919 1.84208821 1.35766244 2.42692947 0.64724806 1.73510319\n",
      " 3.23576689 2.61159327 1.57750585 2.03390141 2.01139531 2.72049161\n",
      " 2.43697269 2.79713061 2.73909138 2.47721867 2.65468987 1.20359525\n",
      " 1.07876306 2.29744664 2.45297804 0.74963121 2.52993533 2.57033217\n",
      " 1.83866214 2.55539939 2.39037147 1.2153654  2.43575107 2.32311787\n",
      " 1.97598527 2.95782966 2.59986542 2.98475837 2.66822556 1.18784406\n",
      " 2.35808984 1.11948127 1.47491148 2.44516767 1.70710187 2.54428403\n",
      " 2.5777445  2.80177077 2.38039896 1.61213358 2.76511005 2.71413\n",
      " 2.53705146 2.33184228 1.59096555 3.09486553 2.6851146  2.40980044\n",
      " 2.44892296 2.07190729 2.56982873 1.4807007  2.56274684 1.81397511\n",
      " 2.75778545 2.44559572 2.636119   2.54709312 2.47312971 1.9378724\n",
      " 3.04680803 2.51123775 2.08240478 2.76147802 0.90309163 2.15656956\n",
      " 2.68514026 3.18881002 1.25207632 1.87394723 2.61848239 2.71188265\n",
      " 0.36669648 2.70155068 2.09584369 2.47934245 1.6308008  1.15155983\n",
      " 2.20192902 1.34918518 2.03963952 2.44677605 1.90176494 0.69856353\n",
      " 1.26744019 2.52261946 1.5743874  0.78713675 1.66071233 1.3607628\n",
      " 1.48082147 1.33468539 1.54210708 2.61469237 2.77080993 2.26882362\n",
      " 2.79769109 2.87360579 1.20168891 2.75168386 2.41949963 2.68431207\n",
      " 2.59702505 2.65994469 2.46920667 2.24312633 1.00345152 1.50397427\n",
      " 2.94083286 3.38969928 1.39218857 2.8681687  1.49921387 1.20768632\n",
      " 2.23590134 2.7516901  2.07428093 0.79669083 2.67363925 2.2060458\n",
      " 2.73048994 1.30132736 1.70839171 2.6585972  1.31151234 1.95869293\n",
      " 1.39595044 1.40083097 1.23800256 1.71084097 1.42163472 2.64004469\n",
      " 2.87002776 2.43003354 2.35318893 2.75847759 1.31924593 1.10988288\n",
      " 2.08725083 3.28622011 0.85678252 1.59230175 2.68441326 2.27409128\n",
      " 2.87418172 2.77501058 1.02447866 1.89890996 1.21776778 1.53560609\n",
      " 1.22832331 3.3744364  2.71213502 1.30448251 2.36304708 3.32885571\n",
      " 2.58410972 1.56303259 1.76435421 2.15448626 2.89626232 1.06199077\n",
      " 2.64396333 2.43476567 2.98903627 2.60416062 2.58316891 2.4005573\n",
      " 3.05970208 2.89864292 2.28131241 2.41651932 1.87030066 2.62136214\n",
      " 1.22690567 0.94941783 2.8047576  1.82633209 2.23998243 2.57196032\n",
      " 1.43637498 3.10921654 1.57536215 2.67572754 1.67118817 3.47101736\n",
      " 3.19841839 3.1074264  1.58391134 3.5328812  3.5194696  2.54783976\n",
      " 3.72845637 2.64633042 1.71288495 3.14318903 3.23059413 3.46279721\n",
      " 2.69246528 2.45391295 2.90606584 1.08220975 1.5041469  1.03074117\n",
      " 2.41689481 3.50444412 2.56095351 3.29258755 0.98259355 0.87934902\n",
      " 1.93222364 2.16106217 2.40569798 2.82082649 0.87511896 3.08382404\n",
      " 3.11093711 2.72796497 0.74259401 2.18646497 3.39199821 3.46286716\n",
      " 3.13755218 2.40411541 2.73449746]\n"
     ]
    }
   ],
   "source": [
    "player_skills = samples['skill'].mean(0)\n",
    "print(player_skills)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the name of the player with the highest skill according to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the highest skill level is:  3.7284563731255114  and his name is:  Aicy\n",
      "the lowest skill level is:  0.20376112743330088  and his name is:  Zest\n"
     ]
    }
   ],
   "source": [
    "ind = np.unravel_index(np.argmax(player_skills, axis=None), player_skills.shape)\n",
    "ind2 = np.unravel_index(np.argmin(player_skills, axis=None), player_skills.shape)\n",
    "\n",
    "print(\"the highest skill level is: \", player_skills[ind[0]], \" and his name is: \", playername[ind[0]])\n",
    "print(\"the lowest skill level is: \", player_skills[ind2[0]], \" and his name is: \", playername[ind2[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above result is surprising because Zest is a good player. According to this link https://www.lineups.com/esports/top-10-starcraft-ii-players-of-all-time/ these are the top ten players of all time. So they should have high skill levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mvp 's skill level is:  0.688391862358984\n",
      "Life 's skill level is:  0.9766454576879855\n",
      "TaeJa 's skill level is:  0.32994991577146243\n",
      "MC 's skill level is:  0.9141929066346802\n",
      "Polt 's skill level is:  0.8801043529185937\n",
      "INnoVation 's skill level is:  0.2296847698131551\n",
      "Zest 's skill level is:  0.20376112743330088\n",
      "NesTea 's skill level is:  0.7355277441125527\n",
      "MMA 's skill level is:  0.6912323114241407\n",
      "Rain 's skill level is:  0.7345775990866452\n"
     ]
    }
   ],
   "source": [
    "top10 = np.array([\n",
    "    playerid[\"Mvp\"],\n",
    "    playerid[\"Life\"],\n",
    "    playerid[\"TaeJa\"],\n",
    "    playerid[\"MC\"],\n",
    "    playerid[\"Polt\"],\n",
    "    playerid[\"INnoVation\"],\n",
    "    playerid[\"Zest\"],\n",
    "    playerid[\"NesTea\"],\n",
    "    playerid[\"MMA\"],\n",
    "    playerid[\"Rain\"]\n",
    "])\n",
    "\n",
    "for id in top10:\n",
    "    print(playername[id], \"'s skill level is: \", player_skills[id])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we're actually getting the opposite of what we were expecting. I think this has to do with the fact that I changed the sampling distribution from bernoulli_logit to binomial_logit. But we can just say that lower is better and still call this a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to predict which player will win, we might use a direct estimator of that quantity based on the sample values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aicy has a  90.96807696567639 % chance of winning against  Zest\n"
     ]
    }
   ],
   "source": [
    "# Player 0 vs Player 1 prediction:\n",
    "def logit(z): return 1./(1.+np.exp(-z))\n",
    "\n",
    "# Use our model's win probability function (logistic of scaled difference)\n",
    "#  using the predicted skill difference for each sample:\n",
    "prob = logit( skill_data['scale']*(samples['skill'][:,ind[0]]-samples['skill'][:,ind2[0]]) ).mean()\n",
    "\n",
    "print(playername[ind[0]], \"has a \", prob * 100, \"% chance of winning against \", playername[ind2[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "according to this link https://liquipedia.net/starcraft2/ESL_Pro_Tour/2020/21/Korea/Standings, Zest is number 3 in the current standings in korea. So the results are definitely reversed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### inversing the skill_levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_skills2 = np.array([1/x for x in player_skills])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the highest skill level is:  4.907707434664347  and his name is:  Zest\n",
      "the lowest skill level is:  0.2682075100054649  and his name is:  Aicy\n"
     ]
    }
   ],
   "source": [
    "ind = np.unravel_index(np.argmax(player_skills2, axis=None), player_skills2.shape)\n",
    "ind2 = np.unravel_index(np.argmin(player_skills2, axis=None), player_skills2.shape)\n",
    "\n",
    "print(\"the highest skill level is: \", player_skills2[ind[0]], \" and his name is: \", playername[ind[0]])\n",
    "print(\"the lowest skill level is: \", player_skills2[ind2[0]], \" and his name is: \", playername[ind2[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mvp 's skill level is:  1.452660983779204\n",
      "Life 's skill level is:  1.023913019948203\n",
      "TaeJa 's skill level is:  3.0307630103856225\n",
      "MC 's skill level is:  1.0938610360489365\n",
      "Polt 's skill level is:  1.1362288990888518\n",
      "INnoVation 's skill level is:  4.353793248082944\n",
      "Zest 's skill level is:  4.907707434664347\n",
      "NesTea 's skill level is:  1.359568021742735\n",
      "MMA 's skill level is:  1.446691630979616\n",
      "Rain 's skill level is:  1.3613265654212354\n"
     ]
    }
   ],
   "source": [
    "top10 = np.array([\n",
    "    playerid[\"Mvp\"],\n",
    "    playerid[\"Life\"],\n",
    "    playerid[\"TaeJa\"],\n",
    "    playerid[\"MC\"],\n",
    "    playerid[\"Polt\"],\n",
    "    playerid[\"INnoVation\"],\n",
    "    playerid[\"Zest\"],\n",
    "    playerid[\"NesTea\"],\n",
    "    playerid[\"MMA\"],\n",
    "    playerid[\"Rain\"]\n",
    "])\n",
    "\n",
    "for id in top10:\n",
    "    print(playername[id], \"'s skill level is: \", player_skills2[id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zest has a  90.9680769656764 % chance of winning against  Aicy\n"
     ]
    }
   ],
   "source": [
    "# Highest skilled player vs Lowest skilled player:\n",
    "def logit(z): return 1./(1.+np.exp(-z))\n",
    "\n",
    "# Use our model's win probability function (logistic of scaled difference)\n",
    "#  using the predicted skill difference for each sample:\n",
    "prob = logit( skill_data['scale']*(samples['skill'][:,ind[0]]-samples['skill'][:,ind2[0]]) ).mean()\n",
    "\n",
    "print(playername[ind[0]], \"has a \", (1-prob) * 100, \"% chance of winning against \", playername[ind2[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
